{"ast":null,"code":"import _objectSpread from \"C:/Users/ashwi/OneDrive/Desktop/LightRiver UI/node_modules/@babel/runtime/helpers/esm/objectSpread2.js\";\n/**\n * @import {Chunk, Event, Token} from 'micromark-util-types'\n */\n\nimport { splice } from 'micromark-util-chunked';\nimport { SpliceBuffer } from './lib/splice-buffer.js';\n\n// Hidden API exposed for testing.\nexport { SpliceBuffer } from './lib/splice-buffer.js';\n\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} eventsArray\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\n// eslint-disable-next-line complexity\nexport function subtokenize(eventsArray) {\n  /** @type {Record<string, number>} */\n  const jumps = {};\n  let index = -1;\n  /** @type {Event} */\n  let event;\n  /** @type {number | undefined} */\n  let lineIndex;\n  /** @type {number} */\n  let otherIndex;\n  /** @type {Event} */\n  let otherEvent;\n  /** @type {Array<Event>} */\n  let parameters;\n  /** @type {Array<Event>} */\n  let subevents;\n  /** @type {boolean | undefined} */\n  let more;\n  const events = new SpliceBuffer(eventsArray);\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n    event = events.get(index);\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (index && event[1].type === \"chunkFlow\" && events.get(index - 1)[1].type === \"listItemPrefix\") {\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === \"lineEndingBlank\") {\n        otherIndex += 2;\n      }\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === \"content\") {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === \"content\") {\n            break;\n          }\n          if (subevents[otherIndex][1].type === \"chunkText\") {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n      while (otherIndex--) {\n        otherEvent = events.get(otherIndex);\n        if (otherEvent[1].type === \"lineEnding\" || otherEvent[1].type === \"lineEndingBlank\") {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events.get(lineIndex)[1].type = \"lineEndingBlank\";\n            }\n            otherEvent[1].type = \"lineEnding\";\n            lineIndex = otherIndex;\n          }\n        } else if (otherEvent[1].type === \"linePrefix\" || otherEvent[1].type === \"listItemIndent\") {\n          // Move past.\n        } else {\n          break;\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = _objectSpread({}, events.get(lineIndex)[1].start);\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        events.splice(lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  }\n\n  // The changes to the `events` buffer must be copied back into the eventsArray\n  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0));\n  return !more;\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {SpliceBuffer<Event>} events\n *   Events.\n * @param {number} eventIndex\n *   Index.\n * @returns {Record<string, number>}\n *   Gaps.\n */\nfunction subcontent(events, eventIndex) {\n  const token = events.get(eventIndex)[1];\n  const context = events.get(eventIndex)[2];\n  let startPosition = eventIndex - 1;\n  /** @type {Array<number>} */\n  const startPositions = [];\n  let tokenizer = token._tokenizer;\n  if (!tokenizer) {\n    tokenizer = context.parser[token.contentType](token.start);\n    if (token._contentTypeTextTrailing) {\n      tokenizer._contentTypeTextTrailing = true;\n    }\n  }\n  const childEvents = tokenizer.events;\n  /** @type {Array<[number, number]>} */\n  const jumps = [];\n  /** @type {Record<string, number>} */\n  const gaps = {};\n  /** @type {Array<Chunk>} */\n  let stream;\n  /** @type {Token | undefined} */\n  let previous;\n  let index = -1;\n  /** @type {Token | undefined} */\n  let current = token;\n  let adjust = 0;\n  let start = 0;\n  const breaks = [start];\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events.get(++startPosition)[1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition);\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n      if (!current.next) {\n        stream.push(null);\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n      tokenizer.write(stream);\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    }\n\n    // Unravel the next token.\n    previous = current;\n    current = current.next;\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token;\n  while (++index < childEvents.length) {\n    if (\n    // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      start = index + 1;\n      breaks.push(start);\n      // Help GC.\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = [];\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n  } else {\n    breaks.pop();\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length;\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    const start = startPositions.pop();\n    jumps.push([start, start + slice.length - 1]);\n    events.splice(start, 2, slice);\n  }\n  jumps.reverse();\n  index = -1;\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n  return gaps;\n}","map":{"version":3,"names":["splice","SpliceBuffer","subtokenize","eventsArray","jumps","index","event","lineIndex","otherIndex","otherEvent","parameters","subevents","more","events","length","get","type","_tokenizer","_isInFirstContentOfListItem","contentType","Object","assign","subcontent","_container","undefined","end","_objectSpread","start","slice","unshift","Number","POSITIVE_INFINITY","eventIndex","token","context","startPosition","startPositions","tokenizer","parser","_contentTypeTextTrailing","childEvents","gaps","stream","previous","current","adjust","breaks","push","sliceStream","next","defineSkip","_gfmTasklistFirstContentOfListItem","write","line","pop","reverse"],"sources":["C:/Users/ashwi/OneDrive/Desktop/LightRiver UI/node_modules/micromark-util-subtokenize/index.js"],"sourcesContent":["/**\n * @import {Chunk, Event, Token} from 'micromark-util-types'\n */\n\nimport { splice } from 'micromark-util-chunked';\nimport { SpliceBuffer } from './lib/splice-buffer.js';\n\n// Hidden API exposed for testing.\nexport { SpliceBuffer } from './lib/splice-buffer.js';\n\n/**\n * Tokenize subcontent.\n *\n * @param {Array<Event>} eventsArray\n *   List of events.\n * @returns {boolean}\n *   Whether subtokens were found.\n */\n// eslint-disable-next-line complexity\nexport function subtokenize(eventsArray) {\n  /** @type {Record<string, number>} */\n  const jumps = {};\n  let index = -1;\n  /** @type {Event} */\n  let event;\n  /** @type {number | undefined} */\n  let lineIndex;\n  /** @type {number} */\n  let otherIndex;\n  /** @type {Event} */\n  let otherEvent;\n  /** @type {Array<Event>} */\n  let parameters;\n  /** @type {Array<Event>} */\n  let subevents;\n  /** @type {boolean | undefined} */\n  let more;\n  const events = new SpliceBuffer(eventsArray);\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n    event = events.get(index);\n\n    // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n    if (index && event[1].type === \"chunkFlow\" && events.get(index - 1)[1].type === \"listItemPrefix\") {\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === \"lineEndingBlank\") {\n        otherIndex += 2;\n      }\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === \"content\") {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === \"content\") {\n            break;\n          }\n          if (subevents[otherIndex][1].type === \"chunkText\") {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    }\n\n    // Enter.\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    }\n    // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n      while (otherIndex--) {\n        otherEvent = events.get(otherIndex);\n        if (otherEvent[1].type === \"lineEnding\" || otherEvent[1].type === \"lineEndingBlank\") {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events.get(lineIndex)[1].type = \"lineEndingBlank\";\n            }\n            otherEvent[1].type = \"lineEnding\";\n            lineIndex = otherIndex;\n          }\n        } else if (otherEvent[1].type === \"linePrefix\" || otherEvent[1].type === \"listItemIndent\") {\n          // Move past.\n        } else {\n          break;\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = {\n          ...events.get(lineIndex)[1].start\n        };\n\n        // Switch container exit w/ line endings.\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        events.splice(lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  }\n\n  // The changes to the `events` buffer must be copied back into the eventsArray\n  splice(eventsArray, 0, Number.POSITIVE_INFINITY, events.slice(0));\n  return !more;\n}\n\n/**\n * Tokenize embedded tokens.\n *\n * @param {SpliceBuffer<Event>} events\n *   Events.\n * @param {number} eventIndex\n *   Index.\n * @returns {Record<string, number>}\n *   Gaps.\n */\nfunction subcontent(events, eventIndex) {\n  const token = events.get(eventIndex)[1];\n  const context = events.get(eventIndex)[2];\n  let startPosition = eventIndex - 1;\n  /** @type {Array<number>} */\n  const startPositions = [];\n  let tokenizer = token._tokenizer;\n  if (!tokenizer) {\n    tokenizer = context.parser[token.contentType](token.start);\n    if (token._contentTypeTextTrailing) {\n      tokenizer._contentTypeTextTrailing = true;\n    }\n  }\n  const childEvents = tokenizer.events;\n  /** @type {Array<[number, number]>} */\n  const jumps = [];\n  /** @type {Record<string, number>} */\n  const gaps = {};\n  /** @type {Array<Chunk>} */\n  let stream;\n  /** @type {Token | undefined} */\n  let previous;\n  let index = -1;\n  /** @type {Token | undefined} */\n  let current = token;\n  let adjust = 0;\n  let start = 0;\n  const breaks = [start];\n\n  // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n  while (current) {\n    // Find the position of the event for this token.\n    while (events.get(++startPosition)[1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition);\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n      if (!current.next) {\n        stream.push(null);\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n      tokenizer.write(stream);\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    }\n\n    // Unravel the next token.\n    previous = current;\n    current = current.next;\n  }\n\n  // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n  current = token;\n  while (++index < childEvents.length) {\n    if (\n    // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      start = index + 1;\n      breaks.push(start);\n      // Help GC.\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  }\n\n  // Help GC.\n  tokenizer.events = [];\n\n  // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n  } else {\n    breaks.pop();\n  }\n\n  // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n  index = breaks.length;\n  while (index--) {\n    const slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    const start = startPositions.pop();\n    jumps.push([start, start + slice.length - 1]);\n    events.splice(start, 2, slice);\n  }\n  jumps.reverse();\n  index = -1;\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n  return gaps;\n}"],"mappings":";AAAA;AACA;AACA;;AAEA,SAASA,MAAM,QAAQ,wBAAwB;AAC/C,SAASC,YAAY,QAAQ,wBAAwB;;AAErD;AACA,SAASA,YAAY,QAAQ,wBAAwB;;AAErD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,SAASC,WAAWA,CAACC,WAAW,EAAE;EACvC;EACA,MAAMC,KAAK,GAAG,CAAC,CAAC;EAChB,IAAIC,KAAK,GAAG,CAAC,CAAC;EACd;EACA,IAAIC,KAAK;EACT;EACA,IAAIC,SAAS;EACb;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,UAAU;EACd;EACA,IAAIC,SAAS;EACb;EACA,IAAIC,IAAI;EACR,MAAMC,MAAM,GAAG,IAAIZ,YAAY,CAACE,WAAW,CAAC;EAC5C,OAAO,EAAEE,KAAK,GAAGQ,MAAM,CAACC,MAAM,EAAE;IAC9B,OAAOT,KAAK,IAAID,KAAK,EAAE;MACrBC,KAAK,GAAGD,KAAK,CAACC,KAAK,CAAC;IACtB;IACAC,KAAK,GAAGO,MAAM,CAACE,GAAG,CAACV,KAAK,CAAC;;IAEzB;IACA;IACA,IAAIA,KAAK,IAAIC,KAAK,CAAC,CAAC,CAAC,CAACU,IAAI,KAAK,WAAW,IAAIH,MAAM,CAACE,GAAG,CAACV,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACW,IAAI,KAAK,gBAAgB,EAAE;MAChGL,SAAS,GAAGL,KAAK,CAAC,CAAC,CAAC,CAACW,UAAU,CAACJ,MAAM;MACtCL,UAAU,GAAG,CAAC;MACd,IAAIA,UAAU,GAAGG,SAAS,CAACG,MAAM,IAAIH,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACQ,IAAI,KAAK,iBAAiB,EAAE;QACxFR,UAAU,IAAI,CAAC;MACjB;MACA,IAAIA,UAAU,GAAGG,SAAS,CAACG,MAAM,IAAIH,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACQ,IAAI,KAAK,SAAS,EAAE;QAChF,OAAO,EAAER,UAAU,GAAGG,SAAS,CAACG,MAAM,EAAE;UACtC,IAAIH,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACQ,IAAI,KAAK,SAAS,EAAE;YAC/C;UACF;UACA,IAAIL,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACQ,IAAI,KAAK,WAAW,EAAE;YACjDL,SAAS,CAACH,UAAU,CAAC,CAAC,CAAC,CAAC,CAACU,2BAA2B,GAAG,IAAI;YAC3DV,UAAU,EAAE;UACd;QACF;MACF;IACF;;IAEA;IACA,IAAIF,KAAK,CAAC,CAAC,CAAC,KAAK,OAAO,EAAE;MACxB,IAAIA,KAAK,CAAC,CAAC,CAAC,CAACa,WAAW,EAAE;QACxBC,MAAM,CAACC,MAAM,CAACjB,KAAK,EAAEkB,UAAU,CAACT,MAAM,EAAER,KAAK,CAAC,CAAC;QAC/CA,KAAK,GAAGD,KAAK,CAACC,KAAK,CAAC;QACpBO,IAAI,GAAG,IAAI;MACb;IACF;IACA;IAAA,KACK,IAAIN,KAAK,CAAC,CAAC,CAAC,CAACiB,UAAU,EAAE;MAC5Bf,UAAU,GAAGH,KAAK;MAClBE,SAAS,GAAGiB,SAAS;MACrB,OAAOhB,UAAU,EAAE,EAAE;QACnBC,UAAU,GAAGI,MAAM,CAACE,GAAG,CAACP,UAAU,CAAC;QACnC,IAAIC,UAAU,CAAC,CAAC,CAAC,CAACO,IAAI,KAAK,YAAY,IAAIP,UAAU,CAAC,CAAC,CAAC,CAACO,IAAI,KAAK,iBAAiB,EAAE;UACnF,IAAIP,UAAU,CAAC,CAAC,CAAC,KAAK,OAAO,EAAE;YAC7B,IAAIF,SAAS,EAAE;cACbM,MAAM,CAACE,GAAG,CAACR,SAAS,CAAC,CAAC,CAAC,CAAC,CAACS,IAAI,GAAG,iBAAiB;YACnD;YACAP,UAAU,CAAC,CAAC,CAAC,CAACO,IAAI,GAAG,YAAY;YACjCT,SAAS,GAAGC,UAAU;UACxB;QACF,CAAC,MAAM,IAAIC,UAAU,CAAC,CAAC,CAAC,CAACO,IAAI,KAAK,YAAY,IAAIP,UAAU,CAAC,CAAC,CAAC,CAACO,IAAI,KAAK,gBAAgB,EAAE;UACzF;QAAA,CACD,MAAM;UACL;QACF;MACF;MACA,IAAIT,SAAS,EAAE;QACb;QACAD,KAAK,CAAC,CAAC,CAAC,CAACmB,GAAG,GAAAC,aAAA,KACPb,MAAM,CAACE,GAAG,CAACR,SAAS,CAAC,CAAC,CAAC,CAAC,CAACoB,KAAK,CAClC;;QAED;QACAjB,UAAU,GAAGG,MAAM,CAACe,KAAK,CAACrB,SAAS,EAAEF,KAAK,CAAC;QAC3CK,UAAU,CAACmB,OAAO,CAACvB,KAAK,CAAC;QACzBO,MAAM,CAACb,MAAM,CAACO,SAAS,EAAEF,KAAK,GAAGE,SAAS,GAAG,CAAC,EAAEG,UAAU,CAAC;MAC7D;IACF;EACF;;EAEA;EACAV,MAAM,CAACG,WAAW,EAAE,CAAC,EAAE2B,MAAM,CAACC,iBAAiB,EAAElB,MAAM,CAACe,KAAK,CAAC,CAAC,CAAC,CAAC;EACjE,OAAO,CAAChB,IAAI;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASU,UAAUA,CAACT,MAAM,EAAEmB,UAAU,EAAE;EACtC,MAAMC,KAAK,GAAGpB,MAAM,CAACE,GAAG,CAACiB,UAAU,CAAC,CAAC,CAAC,CAAC;EACvC,MAAME,OAAO,GAAGrB,MAAM,CAACE,GAAG,CAACiB,UAAU,CAAC,CAAC,CAAC,CAAC;EACzC,IAAIG,aAAa,GAAGH,UAAU,GAAG,CAAC;EAClC;EACA,MAAMI,cAAc,GAAG,EAAE;EACzB,IAAIC,SAAS,GAAGJ,KAAK,CAAChB,UAAU;EAChC,IAAI,CAACoB,SAAS,EAAE;IACdA,SAAS,GAAGH,OAAO,CAACI,MAAM,CAACL,KAAK,CAACd,WAAW,CAAC,CAACc,KAAK,CAACN,KAAK,CAAC;IAC1D,IAAIM,KAAK,CAACM,wBAAwB,EAAE;MAClCF,SAAS,CAACE,wBAAwB,GAAG,IAAI;IAC3C;EACF;EACA,MAAMC,WAAW,GAAGH,SAAS,CAACxB,MAAM;EACpC;EACA,MAAMT,KAAK,GAAG,EAAE;EAChB;EACA,MAAMqC,IAAI,GAAG,CAAC,CAAC;EACf;EACA,IAAIC,MAAM;EACV;EACA,IAAIC,QAAQ;EACZ,IAAItC,KAAK,GAAG,CAAC,CAAC;EACd;EACA,IAAIuC,OAAO,GAAGX,KAAK;EACnB,IAAIY,MAAM,GAAG,CAAC;EACd,IAAIlB,KAAK,GAAG,CAAC;EACb,MAAMmB,MAAM,GAAG,CAACnB,KAAK,CAAC;;EAEtB;EACA;EACA,OAAOiB,OAAO,EAAE;IACd;IACA,OAAO/B,MAAM,CAACE,GAAG,CAAC,EAAEoB,aAAa,CAAC,CAAC,CAAC,CAAC,KAAKS,OAAO,EAAE;MACjD;IAAA;IAEFR,cAAc,CAACW,IAAI,CAACZ,aAAa,CAAC;IAClC,IAAI,CAACS,OAAO,CAAC3B,UAAU,EAAE;MACvByB,MAAM,GAAGR,OAAO,CAACc,WAAW,CAACJ,OAAO,CAAC;MACrC,IAAI,CAACA,OAAO,CAACK,IAAI,EAAE;QACjBP,MAAM,CAACK,IAAI,CAAC,IAAI,CAAC;MACnB;MACA,IAAIJ,QAAQ,EAAE;QACZN,SAAS,CAACa,UAAU,CAACN,OAAO,CAACjB,KAAK,CAAC;MACrC;MACA,IAAIiB,OAAO,CAAC1B,2BAA2B,EAAE;QACvCmB,SAAS,CAACc,kCAAkC,GAAG,IAAI;MACrD;MACAd,SAAS,CAACe,KAAK,CAACV,MAAM,CAAC;MACvB,IAAIE,OAAO,CAAC1B,2BAA2B,EAAE;QACvCmB,SAAS,CAACc,kCAAkC,GAAG3B,SAAS;MAC1D;IACF;;IAEA;IACAmB,QAAQ,GAAGC,OAAO;IAClBA,OAAO,GAAGA,OAAO,CAACK,IAAI;EACxB;;EAEA;EACA;EACAL,OAAO,GAAGX,KAAK;EACf,OAAO,EAAE5B,KAAK,GAAGmC,WAAW,CAAC1B,MAAM,EAAE;IACnC;IACA;IACA0B,WAAW,CAACnC,KAAK,CAAC,CAAC,CAAC,CAAC,KAAK,MAAM,IAAImC,WAAW,CAACnC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,OAAO,IAAImC,WAAW,CAACnC,KAAK,CAAC,CAAC,CAAC,CAAC,CAACW,IAAI,KAAKwB,WAAW,CAACnC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACW,IAAI,IAAIwB,WAAW,CAACnC,KAAK,CAAC,CAAC,CAAC,CAAC,CAACsB,KAAK,CAAC0B,IAAI,KAAKb,WAAW,CAACnC,KAAK,CAAC,CAAC,CAAC,CAAC,CAACoB,GAAG,CAAC4B,IAAI,EAAE;MACjN1B,KAAK,GAAGtB,KAAK,GAAG,CAAC;MACjByC,MAAM,CAACC,IAAI,CAACpB,KAAK,CAAC;MAClB;MACAiB,OAAO,CAAC3B,UAAU,GAAGO,SAAS;MAC9BoB,OAAO,CAACD,QAAQ,GAAGnB,SAAS;MAC5BoB,OAAO,GAAGA,OAAO,CAACK,IAAI;IACxB;EACF;;EAEA;EACAZ,SAAS,CAACxB,MAAM,GAAG,EAAE;;EAErB;EACA;EACA;EACA,IAAI+B,OAAO,EAAE;IACX;IACAA,OAAO,CAAC3B,UAAU,GAAGO,SAAS;IAC9BoB,OAAO,CAACD,QAAQ,GAAGnB,SAAS;EAC9B,CAAC,MAAM;IACLsB,MAAM,CAACQ,GAAG,CAAC,CAAC;EACd;;EAEA;EACA;EACAjD,KAAK,GAAGyC,MAAM,CAAChC,MAAM;EACrB,OAAOT,KAAK,EAAE,EAAE;IACd,MAAMuB,KAAK,GAAGY,WAAW,CAACZ,KAAK,CAACkB,MAAM,CAACzC,KAAK,CAAC,EAAEyC,MAAM,CAACzC,KAAK,GAAG,CAAC,CAAC,CAAC;IACjE,MAAMsB,KAAK,GAAGS,cAAc,CAACkB,GAAG,CAAC,CAAC;IAClClD,KAAK,CAAC2C,IAAI,CAAC,CAACpB,KAAK,EAAEA,KAAK,GAAGC,KAAK,CAACd,MAAM,GAAG,CAAC,CAAC,CAAC;IAC7CD,MAAM,CAACb,MAAM,CAAC2B,KAAK,EAAE,CAAC,EAAEC,KAAK,CAAC;EAChC;EACAxB,KAAK,CAACmD,OAAO,CAAC,CAAC;EACflD,KAAK,GAAG,CAAC,CAAC;EACV,OAAO,EAAEA,KAAK,GAAGD,KAAK,CAACU,MAAM,EAAE;IAC7B2B,IAAI,CAACI,MAAM,GAAGzC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,GAAGwC,MAAM,GAAGzC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC;IACzDwC,MAAM,IAAIzC,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAGD,KAAK,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;EACjD;EACA,OAAOoC,IAAI;AACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}